HDFS Balancers  -- It is done when systems are underutilized
==============
The HDFS balancer re-balances data across the DataNodes, moving blocks from overutilized to underutilized nodes.
As the system administrator, you can run the balancer from the command-line as necessary 
-- for example, after adding new DataNodes to the cluster.

You can run the balancer without parameters, as follows:
sudo -u hdfs hdfs balancer


Note: If Kerberos is enabled, do not use commands in the form sudo -u <user> hadoop <command>;
 they will fail with a security error.
 Instead, use the following commands: 
$ kinit <user> (if you are using a password) 
or
$ kinit -kt <keytab> <principal> (if you are using a keytab) an`d then, 
for each command executed by this user, $ <command>


This runs the balancer with a default threshold of 10%,


each DataNode’s disk usage differs by no more than plus or minus 10 percent 
of the average disk usage in the cluster.

sudo -u hdfs hdfs balancer -threshold 5

Percentage of disk capacity. This overwrites the default threshold.










Setting Maintenance Mode

=========================================



Setting Maintenance Mode enables you to suppress alerts and omit bulk operations for 
specific services, components, and hosts in an Ambari-managed cluster 
when you want to focus on performing hardware or software maintenance,
changing configuration settings, troubleshooting, decommissioning, or removing cluster nodes.


Set Maintenance Mode for a Service

Set Maintenance Mode for a Host


when to turn on maintance mode

You want to perform hardware, firmware, or OS maintenance on a host.
While performing maintenance, you want to be able to do the following:

-->>Prevent alerts generated by all components on this host.

Be able to stop, start, and restart each component on the host.

Prevent host-level or service-level bulk operations from starting, stopping, 
or restarting components on this host.







HDFS Canary -- Default it will run when you start / restart Hadoop services.
=============

This is an HDFS service-level health test that checks that basic client operations are working and 
are completing in a reasonable amount of time. 
This test reports the results of a periodic "canary" test that performs the following sequence of operations.



/tmp/.cloudera_health_monitoring_canary_timestamp. 

-->> HDFS Corrupt Blocks
-->> HDFS DataNode Health
-->> HDFS NameNode Health
-->> HDFS Under-Replicated Blocks
















Rack Awareness

======== in Hadoop HDFS – It is important in case of failure of a complete rack. If you create RACK then 
hadoop will place the block on the different rack. - Fault tolerant

-------------------------

In Big data Hadoop, rack awareness is required for below reasons:

To improve data high availability and reliability.
Improve the performance of the cluster.
To improve network bandwidth.
Avoid losing data if entire rack fails though the chance of the rack failure is far less than that of node failure.
To keep bulk data in the rack when possible.
An assumption that in-rack id’s higher bandwidth, lower latency.





HDFS Quotas Guide
======================

Help in maintaining the size of metadata - otherwise size of metadata will increase.

Name Quotas  -- The name quota is a hard limit on the number of file and directory names in the tree rooted 
		at that directory. 

hdfs dfsadmin -setQuota <N> <directory>...<directory>
hdfs dfsadmin -clrQuota <directory>...<directory>



Space Quotas -- The space quota is a hard limit on the number of bytes used by 
files in the tree rooted at that directory.

hdfs dfsadmin -setSpaceQuota <N> <directory>...<directory>


hdfs dfsadmin -clrSpaceQuota <directory>...<directory>





Reporting Command - An an extension to the count command of the HDFS shell reports quota 
                    values and the current count of names and bytes in use.

hadoop fs -count -q [-h] [-v] <directory>...<directory>

With the -q option, also report the name quota value set for each directory, 










Offline Image Viewer Guide
=================================


The Offline Image Viewer is a tool to dump the contents of hdfs fsimage files to a human-readable format and 
provide read-only WebHDFS API in order to allow offline analysis and examination of an Hadoop cluster’s namespace. 



Reading HDFS - FSImage logs 

hdfs oiv -i fsimage

bin/hdfs dfs -ls webhdfs://127.0.0.1:5978/



Reading HDFS - EDITS logs


hdfs oev  -i edits_logs.







Spark troubleshooting - developer is loading file as a textFile but actual file format is different

-->> there are lot of partitioner are generating , which is making the job delay.

--->> Spark compression technique.

-->>  Unnecessary wide dependendecy are gererating in a cluster. 

-->>   Coolease and re partitioinig






hadoop issue

Namenode - IN the safemode 

1: Thrashold level is not reaching , -- the number of datanode should be live

2: hadoop service are not starting after cluster upgrade.

3: user have created some of unnecssary file on cluster and it is curropted file

hadoop fsck --  chech with the user as well

hadoop fsck --- delete

3:  Attack on the test server . you have lot on unwanted job is running on the cluster. Dr. who



Hive autheration 

1: Storage level autheration  -- we have to create group and permission to this group made to  /user/hive/warehouse/data.db

2: using sentry - role based authentication where we defined role to the user



kerberos authentication

1: Suppose your job will run for 10 hrs but your TGT is going to expire in the 5 hrs , in that case your 
job will fail.

So in the script file - you have to use -  kdestroy and kinit.


2: user is not able to login to cluster

-->> he don't have valid ticket.
-->> his ticket has been expired 





Automation 

1: Monitoring script for user home directoru  level data update -- every uesr will get the 2 GB space, if iti

is greater than 1.5 GB, then adminitraor will update to user regarding his space size.

2: Monitoring script for /tmp directory.





UPGRADE
=======================


Roolling upgrade - It is done rack wise - 10 Nodes at a time , so my cluster will be up and running

Express upgrade - it is done for small cluster. it will stop all the servics , normal duration will be 15 hrs 

of 200 Nodes cluster.








